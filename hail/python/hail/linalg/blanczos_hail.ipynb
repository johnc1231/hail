{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hail as hl\n",
    "from hail import methods\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from math import sqrt, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create genetic data (and clean/process/edit, these cells are retired now, the code to run is in the last cell at the bottom of the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 10:17:45 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 1000 variants...\n",
      "2020-07-27 10:17:45 Hail: INFO: Coerced sorted dataset\n",
      "2020-07-27 10:17:48 Hail: INFO: wrote matrix table with 1000 rows and 100 columns in 8 partitions to balding_nichols_3_100_1000.mt\n"
     ]
    }
   ],
   "source": [
    "# Create genetic data and write to disk\n",
    "bnm_mt = hl.balding_nichols_model(3, 100, 1000)\n",
    "bnm_mt.write(\"balding_nichols_3_100_1000.mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 10:19:25 Hail: WARN: Name collision: field 'sample' already in object dict. \n",
      "  This field must be referenced with __getitem__ syntax: obj['sample']\n"
     ]
    }
   ],
   "source": [
    "# Read first MatrixTable and clean\n",
    "\n",
    "# entries are now calls: An object that represents an individualâ€™s call at a genomic locus\n",
    "mt = hl.read_matrix_table(\"balding_nichols_3_100_1000.mt\")\n",
    "\n",
    "# don't understand meaning of this: returns the count of non-reference alleles from each call\n",
    "mt = mt.transmute_entries(n_alt = hl.float64(mt.GT.n_alt_alleles())) \n",
    "\n",
    "# Turn MatrixTable into Table\n",
    "\n",
    "ht = mt.localize_entries(\"ent\", \"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retired - no longer using for data generation\n",
    "def makeData(model_input, group_size):\n",
    "    mt = hl.balding_nichols_model(*model_input)\n",
    "    mt.write(\"balding_nichols_test.mt\")\n",
    "    mt = hl.read_matrix_table(\"balding_nichols_test.mt\")\n",
    "    mt = mt.transmute_entries(n_alt = hl.float64(mt.GT.n_alt_alleles())) \n",
    "    table = mt.localize_entries(\"ent\", \"sample\")\n",
    "    table = matrix_table_to_table_of_ndarrays(mt.n_alt, group_size, tmp_path='/tmp/test_table.ht')\n",
    "#     table = table.key_by(hl.int32(table.row_group_number))\n",
    "    return table\n",
    "    \n",
    "# data = makeData((3, 100, 1000), 4)\n",
    "\n",
    "# (n, m) = (100, 1000)\n",
    "# k = 50\n",
    "# l = k + 2\n",
    "# q = 0\n",
    "\n",
    "# G = hl.nd.array(np.random.normal(0, 1, (n,l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and NDArray methods from Tim and Dan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for operating with Tables of ndarrays in Hail (from Tim)\n",
    "\n",
    "from hail.expr import Expression, ExpressionException, \\\n",
    "    expr_float64, expr_call, expr_any, expr_numeric, expr_array, \\\n",
    "    expr_locus, \\\n",
    "    analyze, check_entry_indexed, check_row_indexed, \\\n",
    "    matrix_table_source, table_source\n",
    "\n",
    "# Only groups by rows, NOT COLUMNS\n",
    "def matrix_table_to_table_of_ndarrays(field, group_size, tmp_path = '/tmp/nd_table.ht'):\n",
    "    \"\"\"\n",
    "\n",
    "    The returned table has two fields: 'row_group_number' and 'ndarray'.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> ht = matrix_table_to_table_of_ndarrays(mt.GT.n_alt_alleles(), 100)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    field\n",
    "    group_size\n",
    "    tmp_path\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    mt = matrix_table_source('matrix_table_to_table_of_ndarrays/x', field)\n",
    "    mt = mt.select_entries(x = field)\n",
    "    ht = mt.localize_entries(entries_array_field_name='entries')\n",
    "    # now ht.entries is an array of structs with one field, x\n",
    "\n",
    "    # we'll also want to mean-impute/variance-normalize/etc here\n",
    "    ht = ht.select(xs = ht.entries.map(lambda e: e['x']))\n",
    "    # now ht.xs is an array of float64\n",
    "\n",
    "    # now need to produce groups of G\n",
    "    ht = ht.add_index()\n",
    "    ht = ht.group_by(row_group_number= hl.int32(ht.idx // group_size)) \\\n",
    "        .aggregate(ndarray=hl.nd.array(hl.agg.collect(ht.xs)))\n",
    "    # may require a .T on ndarray\n",
    "\n",
    "    return ht.checkpoint(tmp_path, overwrite=True)\n",
    "\n",
    "def chunk_ndarray(a, group_size):\n",
    "    \"\"\"Chunks a NDarray along the first axis in chunks of `group_size`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a\n",
    "    group_size\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    n_groups = a.shape[0] // group_size\n",
    "    groups = []\n",
    "    for i in range(a.shape[0] // group_size):\n",
    "        start = i * group_size\n",
    "        end = (i + 1) * group_size\n",
    "        groups.append(a[start:end, :])\n",
    "    return groups\n",
    "\n",
    "\n",
    "# Concatenate the ndarrays with a blocked Table\n",
    "def concatBlocked(A):\n",
    "    blocks = A.ndarray.collect()\n",
    "    big_mat = np.concatenate(blocks, axis=0)\n",
    "    ht = ndarray_to_table([big_mat])\n",
    "    \n",
    "    block_shape = blocks[0].shape\n",
    "    \n",
    "    tup = ht.ndarray.collect()[0].shape\n",
    "    assert (tup == (len(blocks) * block_shape[0], block_shape[1]))\n",
    "    \n",
    "    return ht\n",
    "\n",
    "def concatToNumpy(A):\n",
    "    blocks = A.ndarray.collect()\n",
    "    big_mat = np.concatenate(blocks, axis=0)\n",
    "    block_shape = blocks[0].shape\n",
    "    num_blocks = len(blocks)\n",
    "    assert big_mat.shape == (num_blocks*block_shape[0], block_shape[1])\n",
    "    return big_mat\n",
    "\n",
    "def ndarray_to_table(chunked_arr):\n",
    "    structs = [hl.struct(row_group_number = idx, ndarray = block)\n",
    "               for idx, block in enumerate(chunked_arr)]\n",
    "    ht = hl.Table.parallelize(structs)\n",
    "    ht = ht.key_by('row_group_number')\n",
    "    return ht\n",
    "\n",
    "# function to multiply two blocks, given the two blocks\n",
    "# returns struct in form of array but not ndarray, includes the shape in the struct\n",
    "# to change the result product directly back into a ndarray we need to use from_column_major\n",
    "def block_product(left, right):\n",
    "    product = left @ right\n",
    "    n_rows, n_cols = product.shape\n",
    "    return hl.struct(\n",
    "        shape=product.shape,\n",
    "        block=hl.range(hl.int(n_rows * n_cols)).map(\n",
    "            lambda absolute: product[absolute % n_rows, absolute // n_rows]))\n",
    "\n",
    "# takes in output of block_product\n",
    "def block_aggregate(prod):\n",
    "    shape = prod.shape\n",
    "    block = prod.block\n",
    "    return hl.nd.from_column_major(\n",
    "        hl.agg.array_sum(block),\n",
    "        hl.agg.take(shape, 1)[0])\n",
    "\n",
    "# returns flat array\n",
    "def to_column_major(ndarray):\n",
    "    n_rows, n_cols = ndarray.shape\n",
    "    return hl.range(hl.int(n_rows * n_cols)).map(\n",
    "        lambda absolute: ndarray[absolute % n_rows, absolute // n_rows])\n",
    "\n",
    "# hl.nd.from_column_major(thing.the_sum, thing.the_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blanczos Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Algorithm step: multiplying H0 = A @ G\n",
    "\n",
    "# METHOD\n",
    "# Multiply a row-blocked matrix by a local non-blocked matrix\n",
    "# First step of algorithm\n",
    "\n",
    "# Usage:\n",
    "# assumes blocks in blocked matrix are named ndarray\n",
    "# A is a table, B is a Hail ndarray\n",
    "# returns a table\n",
    "\n",
    "# Example:\n",
    "# H0 = matmul_rowblocked_nonblocked(data, G)\n",
    "\n",
    "def matmul_rowblocked_nonblocked(A, B):\n",
    "    temp = A.annotate_globals(mat = B)\n",
    "    temp = temp.annotate(ndarray = temp.ndarray @ temp.mat)\n",
    "    temp = temp.select(temp.ndarray)\n",
    "    temp = temp.drop(temp.mat)\n",
    "    return temp\n",
    "\n",
    "\n",
    "# Algorithm step: intermediate operation of multiplying At @ (A @ G) = At @ H0\n",
    "\n",
    "# METHOD\n",
    "# Multiply a column-blocked matrix by a row-blocked matrix \n",
    "# as a blockmatrix multiplcation and then sum\n",
    "# Second step of algorithm\n",
    "\n",
    "# Usage:\n",
    "# pass in matrix A normally, blocked in rows - this specifically expects A to need to be transposed\n",
    "# assumes blocks in blocked matrix are named ndarray\n",
    "# A and B are both tables\n",
    "# returns a hail ndarray\n",
    "\n",
    "# Example:\n",
    "# G1 = matmul_colblocked_rowblocked(data, H0)\n",
    "\n",
    "def matmul_colblocked_rowblocked(A, B):\n",
    "    temp = A.transmute(ndarray = block_product(A.ndarray.transpose(), B[A.row_group_number].ndarray))\n",
    "    result_arr_sum = temp.aggregate(block_aggregate(temp.ndarray))\n",
    "#     blocksA = A.collect()\n",
    "#     blockAshape = blocksA[0].ndarray.shape\n",
    "#     print('A block shape (gets transposed)', blockAshape)\n",
    "#     blockBshape = B.take(1)[0].ndarray.shape\n",
    "#     print('H block shape', blockBshape)\n",
    "#     print(blockAshape[1], blockBshape[1])\n",
    "#     print('shape of blocks in temp', temp.take(1)[0].ndarray.shape)\n",
    "    return result_arr_sum\n",
    "\n",
    "\n",
    "def matmul_nonblocked_rowblocked(B, A):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm step: perform QR decomposition of Hq and compute T = Q^T @ A\n",
    "# Perform QR decomposition of a row-blocked matrix\n",
    "# Third and fourth step of algorithm\n",
    "\n",
    "def computeNextH(A, H):\n",
    "    nextG = matmul_colblocked_rowblocked(A, H)\n",
    "    return matmul_rowblocked_nonblocked(A, nextG)\n",
    "\n",
    "\n",
    "# RETIRED FUNCTIONS FOR NOW\n",
    "\n",
    "\n",
    "# def processH(H, A):\n",
    "    \n",
    "#     # perform QR decomposition on unblocked version of H\n",
    "#     arr_H = concatToNumpy(H)\n",
    "#     Q, R = np.linalg.qr(arr_H)\n",
    "#     # assert(Q.shape == (m, (q+1)*l))\n",
    "    \n",
    "#     # block Q's rows into the same number of blocks that A has\n",
    "#     num_blocks = A.count()\n",
    "#     group_size_Q = Q.shape[0] // num_blocks\n",
    "#     #assert group_size_Q * num_blocks == m\n",
    "#     blocked_Q_table = ndarray_to_table(chunk_ndarray(Q, group_size_Q))\n",
    "    \n",
    "#     T = matmul_colblocked_rowblocked(blocked_Q_table, A)\n",
    "#     U, S, W = np.linalg.svd(T, full_matrices=False)\n",
    "#     V = matmul_rowblocked_nonblocked(blocked_Q_table, U)\n",
    "    \n",
    "#     return V, S, W\n",
    "\n",
    "\n",
    "# Algorithm step: compute SVD of T such that T = USW^T\n",
    "# 5th step of algorithm\n",
    "\n",
    "# def processT(T):\n",
    "#     U, S, W = np.linalg.svd(T, full_matrices=False)\n",
    "#     # assert(U.shape == (l, (q+1)*l))\n",
    "#     # assert(S.shape == ((q+1)*l,))\n",
    "#     # assert(W.shape == ((q+1)*l, n))\n",
    "#     return U, S, W\n",
    "\n",
    "\n",
    "# Algorithm step: multiply V = Q @ W\n",
    "# 6th step of algorithm and last step\n",
    "\n",
    "# def computeV(U, S, W, Q):\n",
    "#     V = matmul_rowblocked_nonblocked(Q, U)\n",
    "#     return V, S, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hailBlanczos(A, G, m, n, k, l, q):\n",
    "    \n",
    "    assert l > k\n",
    "    #assert (q+1)*l <= (n - k)\n",
    "    assert n <= m\n",
    "    \n",
    "    Hi = matmul_rowblocked_nonblocked(A, G)\n",
    "    npH = concatToNumpy(Hi)\n",
    "    for j in range(0, q):\n",
    "        Hj = computeNextH(A, Hi)\n",
    "        npH = np.concatenate((npH, concatToNumpy(Hj)), axis=1)\n",
    "        Hi = Hj\n",
    "    \n",
    "    assert npH.shape == (m, (q+1)*l)\n",
    "    # perform QR decomposition on unblocked version of H\n",
    "    Q, R = np.linalg.qr(npH)\n",
    "    assert Q.shape == (m, (q+1)*l)\n",
    "    \n",
    "    # block Q's rows into the same number of blocks that A has\n",
    "    num_blocks = A.count()\n",
    "    group_size_Q = Q.shape[0] // num_blocks\n",
    "    #assert group_size_Q * num_blocks == m\n",
    "    blocked_Q_table = ndarray_to_table(chunk_ndarray(Q, group_size_Q))\n",
    "    \n",
    "    T = matmul_colblocked_rowblocked(blocked_Q_table, A)\n",
    "    assert(T.shape == ((q+1)*l), n)\n",
    "    U, S, W = np.linalg.svd(T, full_matrices=False)\n",
    "    print(U.shape)\n",
    "    print(S.shape)\n",
    "    print(W.shape)\n",
    "#     assert U.shape == ((q+1)*l, n)\n",
    "#     assert S.shape == (n,)\n",
    "#     assert W.shape == (n, n)\n",
    "    \n",
    "    sing_val = S[k]\n",
    "    \n",
    "    V = matmul_rowblocked_nonblocked(blocked_Q_table, U)\n",
    "    arr_V = concatToNumpy(V)\n",
    "    \n",
    "    truncV = arr_V[:,:k]\n",
    "    truncS = S[:k]\n",
    "    truncW = W[:k,:]\n",
    "    \n",
    "    bound = blanczosErrorB(truncV, np.diag(truncS), truncW.transpose(), m, n, k, q, concatToNumpy(A), sing_val)\n",
    "    print(\"Satisfies Blanczos error bound equation 4.3 if C=1: \", bound)\n",
    "    \n",
    "    print(npH)\n",
    "    print(npH.shape)\n",
    "    \n",
    "    return truncV, truncS, truncW, sing_val, Q\n",
    "\n",
    "# def hailBlanczos(A, G):\n",
    "#     H0 = matmul_rowblocked_nonblocked(A, G)\n",
    "#     T, Q, table_Q = processH(H0, A)\n",
    "#     u, s, w = processT(T)\n",
    "#     V, S, W = computeV(u, s, w, table_Q)\n",
    "#     return V, S, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# T, Q, table_Q = processH(H0, data)\n",
    "# print('Q shape', Q.shape)\n",
    "\n",
    "# u, s, w = processT(T)\n",
    "# V, S, W = computeV(u, s, w, table_Q)\n",
    "# arr_V = concatToNumpy(V)\n",
    "# print('V shape:', arr_V.shape, 'S shape:', S.shape, 'W shape:', W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy implementation from other notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL TRANSPOSED FROM ABOVE IMPLEMENTATION\n",
    "\n",
    "def hwe_normalize(call_expr):\n",
    "    mt = call_expr._indices.source\n",
    "    mt = mt.select_entries(__gt=call_expr.n_alt_alleles())\n",
    "    mt = mt.annotate_rows(__AC=hl.agg.sum(mt.__gt),\n",
    "                          __n_called=hl.agg.count_where(hl.is_defined(mt.__gt)))\n",
    "    mt = mt.filter_rows((mt.__AC > 0) & (mt.__AC < 2 * mt.__n_called))\n",
    "\n",
    "    n_variants = mt.count_rows()\n",
    "    if n_variants == 0:\n",
    "        raise FatalError(\"hwe_normalized: found 0 variants after filtering out monomorphic sites.\")\n",
    "\n",
    "    mt = mt.annotate_rows(__mean_gt=mt.__AC / mt.__n_called)\n",
    "    mt = mt.annotate_rows(\n",
    "        __hwe_scaled_std_dev=hl.sqrt(mt.__mean_gt * (2 - mt.__mean_gt) * n_variants / 2))\n",
    "    mt = mt.unfilter_entries()\n",
    "\n",
    "    normalized_gt = hl.or_else((mt.__gt - mt.__mean_gt) / mt.__hwe_scaled_std_dev, 0.0)\n",
    "    return normalized_gt\n",
    "\n",
    "#Blanczos paper error bound 4.23\n",
    "def blanczosErrorA(U, S, V, m, n, k, q, A, k1th_sing_val):\n",
    "    norm_diff = np.linalg.norm(A - U @ S @ V.transpose())\n",
    "    bound = 100 * l * (((m-k)/l) ** (1/(4*q + 2))) * k1th_sing_val\n",
    "    print('value:', norm_diff, 'bound/upper limit:', bound)\n",
    "    return norm_diff <= bound\n",
    "\n",
    "def blanczosErrorB(U, S, V, m, n, k, q, A, k1th_sing_val):\n",
    "    C = 1\n",
    "    norm_diff = np.linalg.norm(A - U @ S @ V.transpose())\n",
    "    bound = C * (m ** (1/(4*q))) * k1th_sing_val\n",
    "    satisfyingC = norm_diff / bound\n",
    "    print('difference A - USV:', norm_diff, 'bound/upper limit:', bound)\n",
    "    print('C constant needed to satisfy bound:', satisfyingC)\n",
    "    return norm_diff <= bound\n",
    "\n",
    "def normQQtA(A, Q):\n",
    "    return np.linalg.norm(A - Q @ Q.transpose() @ A)\n",
    "\n",
    "def numpyBlanczos(A, m, n, k, l, q, G):\n",
    "\n",
    "    assert l > k\n",
    "    assert (q+1)*l <= (m - k)\n",
    "    assert m <= n\n",
    "\n",
    "    # G = np.random.normal(0, 1, (l, m))\n",
    "    R = G @ A\n",
    "    # AtA = A.transpose() @ A\n",
    "    listR = [R]\n",
    "    for i in range(0, q):\n",
    "        Ri = (listR[i] @ A.transpose()) @ A\n",
    "        listR.append(Ri)\n",
    "        R = np.concatenate((R, Ri), axis=0)\n",
    "\n",
    "    assert(R.shape == ((q+1)*l), n)\n",
    "    (Q, S) = np.linalg.qr(R.transpose())\n",
    "    assert(Q.shape == (n, (q+1)*l))\n",
    "    assert(S.shape == ((q+1)*l, (q+1)*l))\n",
    "\n",
    "    T = A @ Q\n",
    "    assert(T.shape == (m, (q+1)*l))\n",
    "    \n",
    "    (Tu, Ts, Tw) = np.linalg.svd(T, full_matrices=False)\n",
    "    assert Tu.shape, (m, (q+1)*l)\n",
    "    print(Ts.shape)\n",
    "    assert Ts.shape == ((q+1)*l,)\n",
    "    assert Tw.shape == ((q+1)*l, (q+1)*l)\n",
    "    \n",
    "    sing_val = Ts[k]\n",
    "    \n",
    "    V = Q @ Tw\n",
    "    \n",
    "    bound = blanczosErrorB(Tu, np.diag(Ts), V, m, n, k, q, A, sing_val)\n",
    "    print(\"Satisfies Blanczos error bound equation 4.3 if C=1: \", bound)\n",
    "    \n",
    "    return Tu[:,:k], Ts[:k], V[:k,:], sing_val, Q\n",
    "\n",
    "\n",
    "# mt = hl.balding_nichols_model(3, 10000, 1000)\n",
    "# norm_gt = hwe_normalize(mt.GT)\n",
    "# np_matrix = hl.linalg.BlockMatrix.from_entry_expr(norm_gt).to_numpy()\n",
    "\n",
    "# npA = np.asmatrix(np_matrix)\n",
    "# print(npA.shape)\n",
    "# npm, npn = npA.shape\n",
    "# npk = 50\n",
    "# npl = npk + 2\n",
    "# npq = 0\n",
    "\n",
    "# (blanczosU, blanczosS, blanczosV) = blanczosSVD(npA, npm, npn, npk, npl, npq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run NumPy and Hail implementations on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-30 16:18:23 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1500 variants...\n",
      "2020-07-30 16:18:24 Hail: INFO: Coerced sorted dataset\n",
      "2020-07-30 16:18:25 Hail: INFO: wrote matrix table with 1500 rows and 500 columns in 8 partitions to balding_nichols_data.mt\n",
      "2020-07-30 16:18:26 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2020-07-30 16:18:28 Hail: INFO: wrote table with 375 rows in 8 partitions to /tmp/test_table.ht\n"
     ]
    }
   ],
   "source": [
    "def makeSharedData(model_input, block_size):\n",
    "    \n",
    "    # we should have m > n for hail implementation\n",
    "    mt = hl.balding_nichols_model(*model_input)\n",
    "    \n",
    "    mt.write(\"balding_nichols_data.mt\")\n",
    "    mt = hl.read_matrix_table(\"balding_nichols_data.mt\")\n",
    "    \n",
    "    mt = mt.transmute_entries(n_alt = hl.float64(mt.GT.n_alt_alleles())) \n",
    "    table = mt.localize_entries(\"ent\", \"sample\")\n",
    "    table = matrix_table_to_table_of_ndarrays(mt.n_alt, block_size, tmp_path='/tmp/test_table.ht')\n",
    "    # table = table.key_by(hl.int32(table.row_group_number))\n",
    "\n",
    "    # for numpy implementation we want transposed version so m < n\n",
    "    np_matrix = np.asmatrix(concatToNumpy(table).transpose())\n",
    "\n",
    "    return table, np_matrix\n",
    "\n",
    "m = 1500\n",
    "n = 500\n",
    "block_size = 4\n",
    "hailA, numpyA = makeSharedData((3, n, m), block_size)\n",
    "\n",
    "# doesn't account for differences due to transposing\n",
    "# hailV not necessarily supposed to be the same as blanczosU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 30\n",
    "l = k + 2\n",
    "q = 5\n",
    "G = np.random.normal(0, 1, (n,l))\n",
    "(q+1)*l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-30 16:53:35 Hail: INFO: Coerced sorted dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 192)\n",
      "(192,)\n",
      "(192, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-30 16:53:42 Hail: INFO: Coerced sorted dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference A - USV: 479.95933512322597 bound/upper limit: 47.620395220267454\n",
      "C constant needed to satisfy bound: 10.078860809600192\n",
      "Satisfies Blanczos error bound equation 4.3 if C=1:  False\n",
      "[[ 1.85655945e+01  4.33744259e+01 -7.73530726e+00 ...  5.33111350e+30\n",
      "  -1.92248338e+31  7.08423999e+30]\n",
      " [ 1.83043495e+01  2.61983241e+01  2.74185092e+01 ...  6.99198112e+30\n",
      "  -2.52141836e+31  9.29128075e+30]\n",
      " [ 1.85651598e+01  1.90451970e+01  2.78771242e+01 ...  6.12566794e+30\n",
      "  -2.20901221e+31  8.14008214e+30]\n",
      " ...\n",
      " [ 7.51548651e+00 -6.03492638e+00 -1.84074682e+00 ...  6.62240769e+29\n",
      "  -2.38814437e+30  8.80017379e+29]\n",
      " [ 1.95007764e+01  1.92256835e+01  3.54587306e+01 ...  8.63117409e+30\n",
      "  -3.11253713e+31  1.14695192e+31]\n",
      " [ 2.97016606e+01  2.24638550e+01  1.65317403e+01 ...  6.93128718e+30\n",
      "  -2.49953117e+31  9.21062773e+30]]\n",
      "(1500, 192)\n"
     ]
    }
   ],
   "source": [
    "hailV, hailS, hailW, hailSingVal, hailQ = hailBlanczos(hailA, hl.nd.array(G), m, n, k, l, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192,)\n",
      "difference A - USV: 1344.2996326997277 bound/upper limit: 45.04738421678012\n",
      "C constant needed to satisfy bound: 29.841902167517578\n",
      "Satisfies Blanczos error bound equation 4.3 if C=1:  False\n"
     ]
    }
   ],
   "source": [
    "numpyU, numpyS, numpyV, numpySingVal, numpyQ = numpyBlanczos(numpyA, n, m, k, l, q, G.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "largest singular value from hail: 967.4853701356503\n",
      "smallest singular value from hail: 33.11313403874567\n",
      "(30,)\n",
      "(30,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.42108547e-13, -8.52651283e-14,  4.18694091e-03,\n",
       "        1.41952204e-02,  1.36519952e-02,  4.86290621e-02, -9.52093757e-03,\n",
       "       -4.78784745e-02,  2.25612226e-02, -4.82960177e-02, -2.11879055e-02,\n",
       "       -5.18508218e-02, -9.17235545e-02, -5.27615972e-02,  1.26308488e-01,\n",
       "        4.21951592e-02, -9.54389216e-03, -1.08156697e-01, -5.09682138e-02,\n",
       "       -7.54866140e-02, -4.04461179e-02, -7.88173382e-02,  5.55095613e-02,\n",
       "        1.57699216e-02,  2.79714658e-02,  8.01911034e-03,  1.13023507e-01,\n",
       "       -1.06120540e-02, -1.34380798e-02])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('largest singular value from hail:', hailS[0])\n",
    "print('smallest singular value from hail:', hailS[k-1])\n",
    "print(hailS.shape)\n",
    "print(numpyS.shape)\n",
    "hailS - numpyS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392.6023860761228"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normQQtA(numpyA.transpose(), hailQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1500)\n",
      "(1500, 192)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 500 is different from 192)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-467-b65059f27e5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpyA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpyQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnormQQtA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpyA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpyQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-457-6ed1447635b5>\u001b[0m in \u001b[0;36mnormQQtA\u001b[0;34m(A, Q)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormQQtA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnumpyBlanczos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 500 is different from 192)"
     ]
    }
   ],
   "source": [
    "print(numpyA.shape)\n",
    "print(numpyQ.shape)\n",
    "normQQtA(numpyA, numpyQ.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
