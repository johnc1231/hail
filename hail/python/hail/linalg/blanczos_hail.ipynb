{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hail as hl\n",
    "from hail import methods\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from math import sqrt, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE GENETIC DATA (and clean/process/edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 11:34:17 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 1000 variants...\n",
      "2020-07-20 11:34:18 Hail: INFO: Coerced sorted dataset\n",
      "2020-07-20 11:34:21 Hail: INFO: wrote matrix table with 1000 rows and 100 columns in 8 partitions to balding_nichols_3_100_1000.mt\n"
     ]
    }
   ],
   "source": [
    "# Create genetic data and write to disk\n",
    "bnm_mt = hl.balding_nichols_model(3, 100, 1000)\n",
    "bnm_mt.write(\"balding_nichols_3_100_1000.mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'bn': struct {\n",
      "        n_populations: int32, \n",
      "        n_samples: int32, \n",
      "        n_variants: int32, \n",
      "        n_partitions: int32, \n",
      "        pop_dist: array<int32>, \n",
      "        fst: array<float64>, \n",
      "        mixture: bool\n",
      "    }\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    'sample_idx': int32\n",
      "    'pop': int32\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37>\n",
      "    'alleles': array<str>\n",
      "    'ancestral_af': float64\n",
      "    'af': array<float64>\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'n_alt': float64\n",
      "----------------------------------------\n",
      "Column key: ['sample_idx']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Read first MatrixTable and clean\n",
    "\n",
    "# entries are now calls: An object that represents an individualâ€™s call at a genomic locus\n",
    "mt = hl.read_matrix_table(\"balding_nichols_3_100_1000.mt\")\n",
    "\n",
    "# don't understand meaning of this: returns the count of non-reference alleles from each call\n",
    "mt = mt.transmute_entries(n_alt = hl.float64(mt.GT.n_alt_alleles())) \n",
    "\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'bn': struct {\n",
      "        n_populations: int32, \n",
      "        n_samples: int32, \n",
      "        n_variants: int32, \n",
      "        n_partitions: int32, \n",
      "        pop_dist: array<int32>, \n",
      "        fst: array<float64>, \n",
      "        mixture: bool\n",
      "    } \n",
      "    'sample': array<struct {\n",
      "        sample_idx: int32, \n",
      "        pop: int32\n",
      "    }> \n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37> \n",
      "    'alleles': array<str> \n",
      "    'ancestral_af': float64 \n",
      "    'af': array<float64> \n",
      "    'ent': array<struct {\n",
      "        n_alt: float64\n",
      "    }> \n",
      "----------------------------------------\n",
      "Key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 11:34:26 Hail: WARN: Name collision: field 'sample' already in object dict. \n",
      "  This field must be referenced with __getitem__ syntax: obj['sample']\n"
     ]
    }
   ],
   "source": [
    "# Turn MatrixTable into Table\n",
    "\n",
    "ht = mt.localize_entries(\"ent\", \"sample\")\n",
    "ht.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and NDArray methods from Tim and Dan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for operating with Tables of ndarrays in Hail (from Tim)\n",
    "\n",
    "from hail.expr import Expression, ExpressionException, \\\n",
    "    expr_float64, expr_call, expr_any, expr_numeric, expr_array, \\\n",
    "    expr_locus, \\\n",
    "    analyze, check_entry_indexed, check_row_indexed, \\\n",
    "    matrix_table_source, table_source\n",
    "\n",
    "# Only groups by rows, NOT COLUMNS\n",
    "def matrix_table_to_table_of_ndarrays(field, group_size, tmp_path = '/tmp/nd_table.ht'):\n",
    "    \"\"\"\n",
    "\n",
    "    The returned table has two fields: 'row_group_number' and 'ndarray'.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> ht = matrix_table_to_table_of_ndarrays(mt.GT.n_alt_alleles(), 100)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    field\n",
    "    group_size\n",
    "    tmp_path\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    mt = matrix_table_source('matrix_table_to_table_of_ndarrays/x', field)\n",
    "    mt = mt.select_entries(x = field)\n",
    "    ht = mt.localize_entries(entries_array_field_name='entries')\n",
    "    # now ht.entries is an array of structs with one field, x\n",
    "\n",
    "    # we'll also want to mean-impute/variance-normalize/etc here\n",
    "    ht = ht.select(xs = ht.entries.map(lambda e: e['x']))\n",
    "    # now ht.xs is an array of float64\n",
    "\n",
    "    # now need to produce groups of G\n",
    "    ht = ht.add_index()\n",
    "    ht = ht.group_by(row_group_number=ht.idx // group_size) \\\n",
    "        .aggregate(ndarray=hl.nd.array(hl.agg.collect(ht.xs)))\n",
    "    # may require a .T on ndarray\n",
    "\n",
    "    return ht.checkpoint(tmp_path, overwrite=True)\n",
    "\n",
    "def chunk_ndarray(a, group_size):\n",
    "    \"\"\"Chunks a NDarray along the first axis in chunks of `group_size`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a\n",
    "    group_size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    n_groups = a.shape[0] // group_size\n",
    "    groups = []\n",
    "    for i in range(a.shape[0] // group_size):\n",
    "        start = i * group_size\n",
    "        end = (i + 1) * group_size\n",
    "        groups.append(a[start:end, :])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to multiply two blocks, given the two blocks\n",
    "# returns struct in form of array but not ndarray? don't understand last line\n",
    "def block_product(left, right):\n",
    "    product = left @ right\n",
    "    n_rows, n_cols = product.shape\n",
    "    return hl.struct(\n",
    "        shape=product.shape,\n",
    "        block=hl.range(hl.int(n_rows * n_cols)).map(\n",
    "            lambda absolute: product[absolute % n_rows, absolute // n_rows]))\n",
    "\n",
    "def block_aggregate(prod):\n",
    "    shape = prod.shape\n",
    "    block = prod.block\n",
    "    return hl.nd.from_column_major(\n",
    "        hl.agg.array_sum(block),\n",
    "        hl.agg.take(shape, 1)[0])\n",
    "\n",
    "def to_column_major(ndarray):\n",
    "    n_rows, n_cols = ndarray.shape\n",
    "    return hl.range(hl.int(n_rows * n_cols)).map(\n",
    "        lambda absolute: ndarray[absolute % n_rows, absolute // n_rows])\n",
    "\n",
    "# hl.nd.from_column_major(thing.the_sum, thing.the_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 11:34:32 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2020-07-20 11:34:33 Hail: INFO: wrote table with 100 rows in 8 partitions to /tmp/nd_table.ht\n"
     ]
    }
   ],
   "source": [
    "new_ht = matrix_table_to_table_of_ndarrays(mt.n_alt, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'bn': struct {\n",
      "        n_populations: int32, \n",
      "        n_samples: int32, \n",
      "        n_variants: int32, \n",
      "        n_partitions: int32, \n",
      "        pop_dist: array<int32>, \n",
      "        fst: array<float64>, \n",
      "        mixture: bool\n",
      "    } \n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'row_group_number': int64 \n",
      "    'ndarray': ndarray<float64, 2> \n",
      "----------------------------------------\n",
      "Key: ['row_group_number']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "new_ht.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blanczos Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 11:34:33 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 1000 variants...\n",
      "2020-07-20 11:34:34 Hail: INFO: Coerced sorted dataset\n",
      "2020-07-20 11:34:36 Hail: INFO: wrote matrix table with 1000 rows and 100 columns in 8 partitions to balding_nichols_test.mt\n",
      "2020-07-20 11:34:38 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2020-07-20 11:34:40 Hail: INFO: wrote table with 250 rows in 8 partitions to /tmp/test_table.ht\n"
     ]
    }
   ],
   "source": [
    "def makeData(model_input, group_size):\n",
    "    hold_mt = hl.balding_nichols_model(*model_input)\n",
    "    hold_mt.write(\"balding_nichols_test.mt\")\n",
    "    hold_mt = hl.read_matrix_table(\"balding_nichols_test.mt\")\n",
    "    hold_mt = hold_mt.transmute_entries(n_alt = hl.float64(hold_mt.GT.n_alt_alleles())) \n",
    "    table = hold_mt.localize_entries(\"ent\", \"sample\")\n",
    "    return matrix_table_to_table_of_ndarrays(hold_mt.n_alt, group_size, tmp_path='/tmp/test_table.ht')\n",
    "    \n",
    "data = makeData((3, 100, 1000), 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n, m) = (100, 1000)\n",
    "k = 50\n",
    "l = k + 2\n",
    "q = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = hl.nd.array(np.random.normal(0, 1, (n,l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WANT TO DO H0 = A @ G\n",
    "# Multiply a row-blocked matrix by a local non-blocked matrix\n",
    "# First step of algorithm\n",
    "\n",
    "temp_matrix = data.annotate_globals(G = G)\n",
    "# do matrix multiplication by converting from ndarray to array\n",
    "AG = temp_matrix.annotate(prod = block_product(temp_matrix.ndarray, temp_matrix.G))\n",
    "# convert back to ndarray\n",
    "AG = AG.annotate(ndarray = hl.nd.from_column_major(AG.prod.block, hl.agg.take(AG.prod.shape, 1)[0] ))\n",
    "\n",
    "#AG = AG.group_by(AG.prod).aggregate(result = block_aggregate(AG.prod)) # this actually sums all the blocks up\n",
    "\n",
    "\n",
    "# drop extra information\n",
    "AG = AG.select(AG.ndarray)\n",
    "H0 = AG.drop(AG.G)\n",
    "# final_result.describe()\n",
    "# final_result.show() # NOTE: THIS GIVES KeyError 'row' when called - is this from John's ndarray show bug??\n",
    "\n",
    "# assumes blocks in blocked matrix are named ndarray\n",
    "def matmul_rowblocked_nonblocked(A, B):\n",
    "    temp = A.annotate_globals(mat = B)\n",
    "    temp = temp.annotate(prod = block_product(temp.ndarray, temp.mat))\n",
    "    temp = temp.annotate(ndarray = hl.nd.from_column_major(temp.prod.block, hl.agg.take(temp.prod.shape, 1)[0]))\n",
    "    temp = temp.select(temp.ndarray)\n",
    "    temp = temp.drop(temp.mat)\n",
    "    return temp\n",
    "\n",
    "# H0 = matmul_rowblocked_nonblocked(data, G)\n",
    "# H0.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "annotate_globals: keyword argument 'mat': expected expression of type any, found hail.table.Table: <hail.table.Table object at 0x7fd56fd7f590>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExpressionException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/hail/hail/python/hail/expr/expressions/expression_typecheck.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self, x, caller, param)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoerce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mExpressionException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/hail/hail/python/hail/expr/expressions/base_expression.py\u001b[0m in \u001b[0;36mto_expr\u001b[0;34m(e, dtype)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/hail/hail/python/hail/expr/expressions/base_expression.py\u001b[0m in \u001b[0;36mcast_expr\u001b[0;34m(e, dtype)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpute_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/hail/hail/python/hail/expr/expressions/base_expression.py\u001b[0m in \u001b[0;36mimpute_type\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mExpressionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hail cannot automatically impute type of {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExpressionException\u001b[0m: Hail cannot automatically impute type of <class 'hail.table.Table'>: <hail.table.Table object at 0x7fd56fd7f590>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypecheckFailure\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/hail/hail/python/hail/typecheck/check.py\u001b[0m in \u001b[0;36mcheck_all\u001b[0;34m(f, args, kwargs, checks, is_method)\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0mkwargs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwarg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypecheckFailure\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/hail/hail/python/hail/expr/expressions/expression_typecheck.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self, x, caller, param)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mExpressionException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypecheckFailure\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypecheckFailure\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-120a86b17758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Second step of algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate_globals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-1069>\u001b[0m in \u001b[0;36mannotate_globals\u001b[0;34m(self, **named_exprs)\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/hail/hail/python/hail/typecheck/check.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(__original_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__original_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__original_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m__original_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/hail/hail/python/hail/typecheck/check.py\u001b[0m in \u001b[0;36mcheck_all\u001b[0;34m(f, args, kwargs, checks, is_method)\u001b[0m\n\u001b[1;32m    594\u001b[0m                                         \u001b[0margname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwarg_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                                         \u001b[0mexpected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                                         found=checker.format(arg))) from e\n\u001b[0m\u001b[1;32m    597\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: annotate_globals: keyword argument 'mat': expected expression of type any, found hail.table.Table: <hail.table.Table object at 0x7fd56fd7f590>"
     ]
    }
   ],
   "source": [
    "# WANT TO DO intermediate step At @ (A @ G) = At @ H0\n",
    "# Multiply a column-blocked matrix by a row-blocked matrix \n",
    "# as a blockmatrix multiplcation and then sum\n",
    "# Second step of algorithm\n",
    "\n",
    "temp = data.annotate_globals(mat = H0)\n",
    "temp = temp.annotate(prod = block_product(temp.ndarray.transpose(), temp.mat))\n",
    "temp = temp.group_by(temp.prod).aggregate(ndarray = block_aggregate(temp.prod))\n",
    "temp = temp.select(temp.ndarray)\n",
    "temp = temp.drop(temp.mat)\n",
    "\n",
    "\n",
    "# pass in matrix A normally, blocked in rows - this specifically expects A to need to be transposed\n",
    "# assumes blocks in blocked matrix are named ndarray\n",
    "def matmul_colblocked_rowblocked(A, B):\n",
    "    temp = A.annotate_globals(mat = B)\n",
    "    temp = temp.annotate(prod = block_product(temp.ndarray.transpose(), temp.mat))\n",
    "    temp = temp.group_by(temp.prod).aggregate(ndarray = block_aggregate(temp.prod))\n",
    "    temp = temp.select(temp.ndarray)\n",
    "    temp = temp.drop(temp.mat)\n",
    "    return temp\n",
    "\n",
    "#G1 = matmul_colblocked_rowblocked(data, H0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "G.describe()\n",
    "#ht.transmute(ent = ht.ent.map(lambda x: x.n_alt))\n",
    "AG = data.annotate_globals(G = G)\n",
    "AG.describe()\n",
    "AG = AG.annotate(prod = (AG.ndarray @ AG.G))\n",
    "\n",
    "\n",
    "AG.describe()\n",
    "AG.show()\n",
    "matmul_product = AG.aggregate(hl.agg.array_agg(lambda element: hl.agg.sum(element), AG.prod))\n",
    "\n",
    "#(hl.agg.array_sum([data.ndarray @ G]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Scraps - linalg operations on small data, experimenting with Hail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate_{rows, cols, entries}\n",
    "# can annotate without aggregating but can also do an aggregation that is called an annotation?\n",
    "\n",
    "# mt.annotate_rows(sum_of_ef1_by_row=hl.agg.sum(mt.ef1))\n",
    "# Aggregate along each row of entries to create a new row annotation. Can\n",
    "# reference column and entry fields in aggregations.\n",
    "\n",
    "# mt.annotate_cols(sum_of_ef1_by_col=hl.agg.sum(mt.ef1))\n",
    "# Aggregate along each column of entries to create a new col annotation.\n",
    "# Can reference row and entry fields in aggregations\n",
    "\n",
    "# need map-like aggregator to create \"new\" MatrixTable that is a product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice doing a matrix multiplication and a transpose\n",
    "\n",
    "# Make some python ndarrays\n",
    "a = np.arange(30).reshape((5, 6))\n",
    "b = np.arange(24).reshape((6, 4))\n",
    "\n",
    "# Make Hail ndarrays\n",
    "matrix_5_6 = hl.nd.array(a)\n",
    "matrix_6_4 = hl.nd.array(b)\n",
    "\n",
    "# Make MatrixTables from pandas dataframes\n",
    "dfA = pd.DataFrame(data=a[1:,1:], index=a[1:,0], columns=a[0,1:])\n",
    "dfB = pd.DataFrame(data=b[1:,1:], index=b[1:,0], columns=b[0,1:])\n",
    "\n",
    "# How do these hail ndarrys carry across into MatrixTable use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.eval(matrix_5_6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfA\n",
    "# tableA = hl.Table.from_pandas(dfA)\n",
    "# tableA.show()\n",
    "# mtA = tableA.to_matrix_table(row_key=['1'], col_key=['2'])\n",
    "# mtA.describe()\n",
    "# new_htA = matrix_table_to_table_of_ndarrays(mtA.1, 2, PATH???)\n",
    "# tableA.group_by(row_group_number=tableA.idx // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
