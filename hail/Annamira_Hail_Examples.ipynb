{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some things that are helpful to know about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General NDArray stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make a hail ndarray from a numpy ndarray. This will probably be useful for what Patrick was mentioning about being able to use the same random matrix in both numpy and hail. Just generate a random matrix in numpy and then use `hl.nd.array` to turn it into a hail ndarray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hnd = hl.nd.array(np.arange(20).reshape((4, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a single hail ndarray, you can use `eval` to turn it into a numpy array. `eval` is never really used in production hail pipelines with tables and whatnot, it's just used to experiment with small values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Hail with default parameters...\n",
      "Running on Apache Spark version 2.4.0\n",
      "SparkUI available at http://192.168.0.12:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.49-8cdca2917be5\n",
      "LOGGING: writing to /Users/johnc/Code/hail/hail/hail-20200710-1051-0.2.49-8cdca2917be5.log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.eval(hnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful: `show` is currently broken for ndarrays (the data prints in the wrong order). Just use `eval` if it's a single ndarray or `collect` when you have a table of ndarrays and you want to look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;\"></div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \" colspan=\"1\"><div style=\"text-align: left;border-bottom: solid 2px #000; padding-bottom: 5px\"><expr></div></td></tr><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; text-align: left;\">ndarray&lt;int64, 2&gt;</td></tr>\n",
       "</thead><tbody><tr><td style=\"white-space: nowrap; max-width: 500px; overflow: hidden; text-overflow: ellipsis; \">ndarray{shape=(4, 5), data=[[0, 5, 10, 15, 1], [6, 11, 16, 2, 7], [12, 17, 3, 8, 13], [18, 4, 9, 14, 19]]}</td></tr>\n",
       "</tbody></table>"
      ],
      "text/plain": [
       "+------------------------------------------------------------------------------------------------------------+\n",
       "| <expr>                                                                                                     |\n",
       "+------------------------------------------------------------------------------------------------------------+\n",
       "| ndarray<int64, 2>                                                                                          |\n",
       "+------------------------------------------------------------------------------------------------------------+\n",
       "| ndarray{shape=(4, 5), data=[[0, 5, 10, 15, 1], [6, 11, 16, 2, 7], [12, 17, 3, 8, 13], [18, 4, 9, 14, 19]]} |\n",
       "+------------------------------------------------------------------------------------------------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hnd.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hail array can also be turned into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "hail_array = hl.array(hl.range(10))\n",
    "print(hl.eval(hail_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.eval(hl.nd.array(hail_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested arrays work too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nested_hail_array = hl.range(10).map(lambda x: hl.range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4],\n",
       " [0, 1, 2, 3, 4]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.eval(nested_hail_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl.eval(hl.nd.array(nested_hail_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with Tables and MatrixTables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider checking the cheat sheets, they're helpful: https://hail.is/docs/0.2/cheatsheets.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How do I get a matrixtable to experiment with?\n",
    "\n",
    "A: I'd probably use balding nichols to generate a matrix, then write it to disk. Then just read it in for future computation, that way it's deterministic. So just do the write part once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-10 11:04:44 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 1000 variants...\n"
     ]
    }
   ],
   "source": [
    "bnm_mt = hl.balding_nichols_model(3, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-10 11:05:07 Hail: INFO: Coerced sorted dataset\n",
      "2020-07-10 11:05:08 Hail: INFO: wrote matrix table with 1000 rows and 100 columns in 8 partitions to balding_nichols_3_100_1000.mt\n"
     ]
    }
   ],
   "source": [
    "bnm_mt.write(\"balding_nichols_3_100_1000.mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mt = hl.read_matrix_table(\"balding_nichols_3_100_1000.mt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How do I check how my data is structured?\n",
    "\n",
    "A: Use `describe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'bn': struct {\n",
      "        n_populations: int32, \n",
      "        n_samples: int32, \n",
      "        n_variants: int32, \n",
      "        n_partitions: int32, \n",
      "        pop_dist: array<int32>, \n",
      "        fst: array<float64>, \n",
      "        mixture: bool\n",
      "    }\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    'sample_idx': int32\n",
      "    'pop': int32\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37>\n",
      "    'alleles': array<str>\n",
      "    'ancestral_af': float64\n",
      "    'af': array<float64>\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'GT': call\n",
      "----------------------------------------\n",
      "Column key: ['sample_idx']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the single entry field is GT, which is a call. You're going to want a number instead. Let's replace GT with a new field `n_alt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'bn': struct {\n",
      "        n_populations: int32, \n",
      "        n_samples: int32, \n",
      "        n_variants: int32, \n",
      "        n_partitions: int32, \n",
      "        pop_dist: array<int32>, \n",
      "        fst: array<float64>, \n",
      "        mixture: bool\n",
      "    }\n",
      "----------------------------------------\n",
      "Column fields:\n",
      "    'sample_idx': int32\n",
      "    'pop': int32\n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37>\n",
      "    'alleles': array<str>\n",
      "    'ancestral_af': float64\n",
      "    'af': array<float64>\n",
      "----------------------------------------\n",
      "Entry fields:\n",
      "    'n_alt': float64\n",
      "----------------------------------------\n",
      "Column key: ['sample_idx']\n",
      "Row key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mt = mt.transmute_entries(n_alt = hl.float64(mt.GT.n_alt_alleles()))\n",
    "mt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How do I turn a matrix table into a table?\n",
    "\n",
    "A: There's more than one way, but I think you want `_localize_entries`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ht = mt.localize_entries(\"ent\", \"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'bn': struct {\n",
      "        n_populations: int32, \n",
      "        n_samples: int32, \n",
      "        n_variants: int32, \n",
      "        n_partitions: int32, \n",
      "        pop_dist: array<int32>, \n",
      "        fst: array<float64>, \n",
      "        mixture: bool\n",
      "    } \n",
      "    'sample': array<struct {\n",
      "        sample_idx: int32, \n",
      "        pop: int32\n",
      "    }> \n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37> \n",
      "    'alleles': array<str> \n",
      "    'ancestral_af': float64 \n",
      "    'af': array<float64> \n",
      "    'ent': array<struct {\n",
      "        n_alt: float64\n",
      "    }> \n",
      "----------------------------------------\n",
      "Key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ht.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how previously, we had an entry field called `n_alt` that was a `float64`, but now we just have a row field that is an `array<struct{n_alt: float64}>`. The struct is unnecessary though, let's remove that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ht = ht.transmute(ent = ht.ent.map(lambda x: x.n_alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'bn': struct {\n",
      "        n_populations: int32, \n",
      "        n_samples: int32, \n",
      "        n_variants: int32, \n",
      "        n_partitions: int32, \n",
      "        pop_dist: array<int32>, \n",
      "        fst: array<float64>, \n",
      "        mixture: bool\n",
      "    } \n",
      "    'sample': array<struct {\n",
      "        sample_idx: int32, \n",
      "        pop: int32\n",
      "    }> \n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37> \n",
      "    'alleles': array<str> \n",
      "    'ancestral_af': float64 \n",
      "    'af': array<float64> \n",
      "    'ent': array<float64> \n",
      "----------------------------------------\n",
      "Key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ht.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think you're going to need an undocumented function called `_group_within_partitions`. It takes a table of rows and groups several adjacent rows together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ght = ht._group_within_partitions(\"group_field\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'bn': struct {\n",
      "        n_populations: int32, \n",
      "        n_samples: int32, \n",
      "        n_variants: int32, \n",
      "        n_partitions: int32, \n",
      "        pop_dist: array<int32>, \n",
      "        fst: array<float64>, \n",
      "        mixture: bool\n",
      "    } \n",
      "    'sample': array<struct {\n",
      "        sample_idx: int32, \n",
      "        pop: int32\n",
      "    }> \n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37> \n",
      "    'alleles': array<str> \n",
      "    'group_field': array<struct {\n",
      "        locus: locus<GRCh37>, \n",
      "        alleles: array<str>, \n",
      "        ancestral_af: float64, \n",
      "        af: array<float64>, \n",
      "        ent: array<float64>\n",
      "    }> \n",
      "----------------------------------------\n",
      "Key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ght.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there's a field called `group_field` that contains an array of structs, where the `struct`'s fields are the old row fields. The arrays are of maximum length 10, as specified as an argument to `_group_within_partitions`. Now that you have an array of arrays, you can make ndarrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ght = ght.annotate(ent_nd = hl.nd.array(ght.group_field.map(lambda x: x.ent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Global fields:\n",
      "    'bn': struct {\n",
      "        n_populations: int32, \n",
      "        n_samples: int32, \n",
      "        n_variants: int32, \n",
      "        n_partitions: int32, \n",
      "        pop_dist: array<int32>, \n",
      "        fst: array<float64>, \n",
      "        mixture: bool\n",
      "    } \n",
      "    'sample': array<struct {\n",
      "        sample_idx: int32, \n",
      "        pop: int32\n",
      "    }> \n",
      "----------------------------------------\n",
      "Row fields:\n",
      "    'locus': locus<GRCh37> \n",
      "    'alleles': array<str> \n",
      "    'group_field': array<struct {\n",
      "        locus: locus<GRCh37>, \n",
      "        alleles: array<str>, \n",
      "        ancestral_af: float64, \n",
      "        af: array<float64>, \n",
      "        ent: array<float64>\n",
      "    }> \n",
      "    'ent_nd': ndarray<float64, 2> \n",
      "----------------------------------------\n",
      "Key: ['locus', 'alleles']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ght.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('hail': conda)",
   "language": "python",
   "name": "python37364bithailconda0cc0b02782f24db785ce7af175b6d4ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
